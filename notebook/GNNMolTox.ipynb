{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQl01Qv53E64wXYZMmZqym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuckyNugget/Toxicity-Prediction-GNN-/blob/main/notebook/GNNMolTox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Core Dependencies"
      ],
      "metadata": {
        "id": "gq9eF-jsv-QT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITPHgjtAvXTp"
      },
      "outputs": [],
      "source": [
        "# 1. Install RDKit (Cheminformatics engine)\n",
        "!pip install -q rdkit\n",
        "\n",
        "\n",
        "# 2. Install PyTorch Geometric (The GNN framework)\n",
        "!pip install -q torch_geometric\n",
        "\n",
        "# 3. Install DeepChem & PubChemPy (For the data)\n",
        "!pip install deepchem pubchempy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "bcbELWiFwLrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import required libraries\n",
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# RDKit for molecular handling\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "# PyTorch and PyTorch Geometric\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import MoleculeNet\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "#import pytorch libraries\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "\n",
        "# NetworkX for graph visualization\n",
        "import networkx as nx\n",
        "\n",
        "# IPython display utilities\n",
        "from IPython.display import display\n",
        "\n",
        "# Pubchem for data\n",
        "import pubchempy as pcp\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_context(\"notebook\", font_scale=1.5)\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "inQV2AERwNtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T8exCxPiwW6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download the CSV directly (Bypassing DeepChem's loader)\n",
        "url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\"\n",
        "print(f\"Downloading data from {url}...\")\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 2. Inspect the data\n",
        "print(f\"Loaded {len(df)} rows.\")\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# The 'smiles' column has the molecule structure\n",
        "# The other columns (NR-AR, SR-ARE, etc.) are the 12 toxicity labels\n",
        "labels_cols = [c for c in df.columns if c != 'smiles' and c != 'mol_id']\n",
        "print(f\"Toxicity Tasks found: {len(labels_cols)}\")\n",
        "\n",
        "\n",
        "# Lesson learned\n",
        "# I was unable to actually load the data because I kept running into a\n",
        "# simple error where edge cases prevented me from loading in the data fully\n",
        "# so I had to manually use pandas\n"
      ],
      "metadata": {
        "id": "wRdXp46_whue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turning the smiles into actual data that can be processed into the graph\n",
        "\n",
        "def advanced_smiles_to_graph(smiles: str):\n",
        "\n",
        "  # Create RDkit molecule from SMILES string\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  if mol is None:\n",
        "    raise ValueError(f\"could not get moelcule\")\n",
        "\n",
        "  # Add hydrogens\n",
        "  mol = Chem.AddHs(mol)\n",
        "\n",
        "  # One hot encoding for each bond type\n",
        "  bond_type_to_idx = {\n",
        "      Chem.rdchem.BondType.SINGLE: 0,\n",
        "      Chem.rdchem.BondType.DOUBLE: 1,\n",
        "      Chem.rdchem.BondType.TRIPLE: 2,\n",
        "      Chem.rdchem.BondType.AROMATIC: 3,\n",
        "  }\n",
        "\n",
        "  # Get total number of atoms\n",
        "  n_atoms = mol.GetNumAtoms()\n",
        "\n",
        "  # Intialize list to store node atom features\n",
        "  node_features = []\n",
        "  for atom in mol.GetAtoms():\n",
        "    # Extract basic atom properoties\n",
        "    atom_type = atom.GetSymbol()\n",
        "    atomic_num = atom.GetAtomicNum()\n",
        "    formal_charge = atom.GetFormalCharge()\n",
        "    hybridization = atom.GetHybridization()\n",
        "    is_aromatic = int(atom.GetIsAromatic())\n",
        "    is_in_ring = int(atom.IsInRing())\n",
        "\n",
        "    # Create one-hot encoding for common atom types\n",
        "    atom_types = ['C', 'O', 'N', 'H', 'F', 'P', 'S', 'Cl', 'Br', 'I']\n",
        "    atom_type_onehot = [1 if atom_type == t else 0 for t in atom_types]\n",
        "\n",
        "    if atom_type not in atom_types:\n",
        "        atom_type_onehot.append(1)  # \"Other\" category\n",
        "    else:\n",
        "        atom_type_onehot.append(0)\n",
        "\n",
        "    # Create one-hot encoding for hybridization states\n",
        "    hybridization_types = [\n",
        "        Chem.rdchem.HybridizationType.SP,\n",
        "        Chem.rdchem.HybridizationType.SP2,\n",
        "        Chem.rdchem.HybridizationType.SP3\n",
        "    ]\n",
        "\n",
        "    hybridization_onehot = [1 if hybridization == h else 0 for h in hybridization_types]\n",
        "    if hybridization not in hybridization_types:\n",
        "        hybridization_onehot.append(1)  # \"Other\" hybridization\n",
        "    else:\n",
        "        hybridization_onehot.append(0)\n",
        "\n",
        "    # Combine all atomic features into a single feature vector\n",
        "    features = atom_type_onehot + [\n",
        "        formal_charge,\n",
        "        is_aromatic,\n",
        "        is_in_ring,\n",
        "        atom.GetDegree(),\n",
        "        atom.GetTotalNumHs(),\n",
        "        atom.GetNumRadicalElectrons()  # Number of unpaired electrons\n",
        "    ] + hybridization_onehot\n",
        "\n",
        "    # This is concatenation so the arrays all merge to gather to form a super array\n",
        "    node_features.append(features)\n",
        "\n",
        "  # Convert node features to numpy array for efficient computation\n",
        "  node_features = np.array(node_features)\n",
        "\n",
        "  # Initialize data structures for edge information\n",
        "  adjacency = np.zeros((n_atoms, n_atoms))  # Adjacency matrix, prob don't need (only for visualization)\n",
        "  edge_features = []                        # List to store bond features\n",
        "  edge_indices = []\n",
        "\n",
        "  # Process each bond in the molecule\n",
        "  for bond in mol.GetBonds():\n",
        "\n",
        "      # Get indices of atoms involved in the bond\n",
        "      begin_idx = bond.GetBeginAtomIdx()\n",
        "      end_idx = bond.GetEndAtomIdx()\n",
        "\n",
        "      # Update adjacency matrix (symmetric for undirected graph)\n",
        "      #adjacency[begin_idx, end_idx] = 1 DELETD CAUSE NOT NEEDED\n",
        "      #adjacency[end_idx, begin_idx] = 1\n",
        "\n",
        "      # Create one-hot encoding for bond type\n",
        "      bond_type = bond.GetBondType()\n",
        "      bond_type_onehot = np.zeros(len(bond_type_to_idx))\n",
        "      if bond_type in bond_type_to_idx:\n",
        "          bond_type_onehot[bond_type_to_idx[bond_type]] = 1\n",
        "\n",
        "      # Extract additional bond properties\n",
        "      is_conjugated = int(bond.GetIsConjugated())  # Whether bond is part of a conjugated system\n",
        "      is_in_ring = int(bond.IsInRing())           # Whether bond is part of a ring\n",
        "\n",
        "      # Combine all bond features\n",
        "      features = np.concatenate([bond_type_onehot, [is_conjugated, is_in_ring]])\n",
        "\n",
        "      # Add edge in both directions (undirected graph representation)\n",
        "      edge_features.append(features)\n",
        "      edge_indices.append((begin_idx, end_idx))\n",
        "\n",
        "      edge_features.append(features)  # Same feature for the reverse direction\n",
        "      edge_indices.append((end_idx, begin_idx))\n",
        "\n",
        "      # ^^ Interestingly, Undirected function does not actually fully resolve this because it cannnot\n",
        "      # handle edge cases where there are no edge features\n",
        "\n",
        "  # Convert edge features to numpy array, handling empty case\n",
        "  if edge_features:\n",
        "      edge_features = np.array(edge_features)\n",
        "  else:\n",
        "      edge_features = np.empty((0, len(bond_type_to_idx) + 2))  # +2 for conjugation and ring features\n",
        "\n",
        "  return node_features, adjacency, edge_features, edge_indices\n"
      ],
      "metadata": {
        "id": "9hkKKqRX21K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#need to now take these smiles and input them into pyg format\n",
        "\n",
        "def smiles_to_pyg(smiles:str, label=None):\n",
        "\n",
        "  try:\n",
        "    # Get the graph representation of smiles\n",
        "    node_features, adjacency, edge_features, edge_indices = advanced_smiles_to_graph(smiles)\n",
        "  except ValueError:\n",
        "    return None\n",
        "\n",
        "  # Put into tesnor because it allows easier calculations\n",
        "  x = torch.tensor(node_features, dtype=torch.float)\n",
        "\n",
        "  # Convert edge indices to pytorch tensor in COO format\n",
        "  # edge_index is a 2 x n row list that contains source and target nodes\n",
        "  # .t() transposes the matrix and .contiguous() ensures memory layout is optimal\n",
        "  edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "\n",
        "  # Convert edge features to PyTorch Tensor\n",
        "  edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
        "\n",
        "  # HANDLE THE LABEL (Crucial for Training)\n",
        "  y = None\n",
        "  if label is not None:\n",
        "    # Convert label to float tensor (handle NaNs later if needed)\n",
        "    y = torch.tensor(label, dtype=torch.float).view(1, -1)\n",
        "\n",
        "  # Create PyG Data object\n",
        "  # x: node features\n",
        "  # edge_index: graph connectivity\n",
        "  # edge_attr: edge features\n",
        "  # smiles: original SMILES string (stored for reference)\n",
        "  data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, smiles=smiles)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "-3ZnVx_d2t9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run to generate final training set\n",
        "\n",
        "# Identify Label Columns\n",
        "label_cols = [c for c in df.columns if c not in ['smiles', 'mol_id']]\n",
        "\n",
        "# Process the DataFrame\n",
        "print(f\"Processing {len(df)} molecules ...\")\n",
        "data_list = []\n",
        "\n",
        "# Gets index and row where index is 0,1,2,... and row is the actual row of values\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "  # Gets the actual smiles for that specific row\n",
        "  smiles = row['smiles']\n",
        "\n",
        "  # Gets all the label values for this moelcule, replaces any missing values with -1,\n",
        "  # Converts from panda series to numpy arra\n",
        "  labels = row[labels_cols].fillna(-1).values\n",
        "\n",
        "  # Takes the smiles and and the labels and outputs it.\n",
        "  graph_data = smiles_to_pyg(smiles, label=labels)\n",
        "\n",
        "  # Add to list if valid\n",
        "  if graph_data is not None:\n",
        "    data_list.append(graph_data)\n",
        "\n",
        "  # Progress tracking\n",
        "  if index% 1000 == 0:\n",
        "    print(f\"   Processed {index}...\")\n",
        "\n",
        "print(f\"âœ… Done! Created {len(data_list)} valid graph objects.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0q71HtyBVcY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicityGAT(torch.nn.Module):\n",
        "  def __init__(self, num_node_features, hidden_channels = 64, num_classes = 12):\n",
        "    super(ToxicityGAT, self).__init__()\n",
        "\n",
        "    #each conv has an attention mechanism\n",
        "\n",
        "    # Layer 1: Input layer -> Hidden Layer\n",
        "    # heads=4 means we use \"Multi-Head Attention\" (4 different views of the molecule)\n",
        "    self.conv1 = GATConv(num_node_features, hidden_channels, heads=4, dropout=0.1)\n",
        "\n",
        "    # Batch Norm acts as a \"Reset\" button to keep numbers stable\n",
        "    self.bn1 = torch.nn.BatchNorm1d(hidden_channels * 4)\n",
        "\n",
        "    # Layer 2: Hidden -> Hidden\n",
        "    # We multiply hidden_channels by 4 because the previous layer had 4 heads\n",
        "    self.conv2 = GATConv(hidden_channels * 4, hidden_channels, heads=4, dropout=0.1)\n",
        "    self.bn2 = torch.nn.BatchNorm1d(hidden_channels * 4)\n",
        "\n",
        "    # Layer 3: Hidden -> Hidden (Refining the features)\n",
        "    self.conv3 = GATConv(hidden_channels * 4, hidden_channels, heads=1, dropout=0.1)\n",
        "\n",
        "    # Output Layer: Map to the 12 toxicity tasks\n",
        "    self.lin = torch.nn.Linear(hidden_channels, num_classes) #no attention mechanism\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "\n",
        "        # Message Passing (The Graph Layers)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x) # Normalize\n",
        "        x = F.elu(x) # ELU is often better than ReLU for GATs\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "\n",
        "        x_in = x\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.elu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # Global Pooling (Graph -> Vector)\n",
        "        # This collapses the ~20 atoms into a single vector representing the WHOLE molecule\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Final Classification\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x # We return Raw Logits (we'll apply Sigmoid in the loss function)"
      ],
      "metadata": {
        "id": "_CrSO9ICBU7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of features from your first graph\n",
        "# (This comes from your advanced_smiles_to_graph function)\n",
        "num_features = data_list[0].num_node_features\n",
        "print(f\"Each atom has {num_features} features.\")\n",
        "\n",
        "# Instantiate the model\n",
        "model = ToxicityGAT(num_node_features=num_features)\n",
        "print(\"Model initialized successfully!\")\n",
        "\n",
        "# Test on a single batch to ensure no shape errors\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "test_loader = DataLoader(data_list[:32], batch_size=32)\n",
        "batch = next(iter(test_loader))\n",
        "\n",
        "# Pass the batch through the model\n",
        "output = model(batch.x, batch.edge_index, batch.batch)\n",
        "\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "# Should be [32, 12] -> (32 molecules, 12 toxicity tasks)"
      ],
      "metadata": {
        "id": "EBtH5GDuB2hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Shuffle and Split\n",
        "import random\n",
        "random.shuffle(data_list)\n",
        "\n",
        "split_idx = int(len(data_list) * 0.8)\n",
        "train_dataset = data_list[:split_idx]\n",
        "test_dataset = data_list[split_idx:]\n",
        "\n",
        "# Create Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize Model & Optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# Get number of features from the first graph\n",
        "num_features = data_list[0].num_node_features\n",
        "model = ToxicityGAT(num_node_features=num_features).to(device)\n",
        "\n",
        "# Adam is the standard optimizer for GNNs (learn more!)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "# Reduce LR if the loss stops going down for 5 epochs\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "# BCEWithLogitsLoss is required for Multi-Label Binary Classification\n",
        "# (combines Sigmoid + Binary Cross Entropy for stability)\n",
        "num_pos = 1  # Toxic\n",
        "num_neg = 15 # Safe\n",
        "weight = torch.tensor([num_neg / num_pos], dtype=torch.float).to(device)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weight) #should look WAY more into this"
      ],
      "metadata": {
        "id": "lZjyWauqCYbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Pass\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "\n",
        "        # Create Mask for Valid Labels\n",
        "        # We only want to calculate loss where y != -1\n",
        "        y = batch.y\n",
        "        is_labeled = y != -1 # Creates a True/False matrix\n",
        "\n",
        "        # Calculate Loss (Only on valid data)\n",
        "        # We slice both 'out' and 'y' using the mask\n",
        "        loss = criterion(out[is_labeled], y[is_labeled])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# Setup Variables\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "patience_limit = 10  # Stop if no improvement for 10 epochs\n",
        "\n",
        "# Running\n",
        "print(\"Starting Training...\")\n",
        "for epoch in range(1, 51):\n",
        "    train_loss = train()\n",
        "\n",
        "    if train_loss < best_val_loss:\n",
        "      best_val_loss = train_loss\n",
        "      patience_counter = 0\n",
        "\n",
        "      torch.save(model.state_dict(), 'best_toxicity_model.pth')\n",
        "\n",
        "    else:\n",
        "      patience_counter+=1\n",
        "\n",
        "    # Emergency break\n",
        "    if patience_counter >= patience_limit:\n",
        "        print(f\"ðŸ›‘ Early Stopping triggered at Epoch {epoch}!\")\n",
        "        break\n",
        "\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    #general printing of EPOCHS, LOSS, and Learning Rate\n",
        "    if epoch % 2 == 0:\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch} | Loss: {train_loss:.4f} | LR: {current_lr:.6f}\")"
      ],
      "metadata": {
        "id": "jLaoIXHWC80s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate():\n",
        "\n",
        "    # Turn on evaluation protocol\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "\n",
        "    #no point in keeping track of grads cause it uses memory\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            #however models output negastive to positive values\n",
        "\n",
        "            # Apply Sigmoid to turn Logits into Probabilities (0 to 1)\n",
        "            pred = torch.sigmoid(out)\n",
        "\n",
        "            y_true.append(batch.y.cpu().numpy())\n",
        "            y_pred.append(pred.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "\n",
        "    # Combining them vertically\n",
        "\n",
        "    # After concatenation you get a single 2d array not a list\n",
        "    y_true = np.concatenate(y_true, axis=0)\n",
        "    y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "    # Calculate ROC-AUC for each of the 12 tasks\n",
        "    roc_scores = []\n",
        "    for i in range(12):\n",
        "        # Only evaluate on valid labels (ignore -1)\n",
        "        valid_mask = y_true[:, i] != -1\n",
        "        if valid_mask.sum() > 0: #checking to see if there is at least one valid data point\n",
        "\n",
        "            score = roc_auc_score(y_true[valid_mask, i], y_pred[valid_mask, i])# calculate score\n",
        "            roc_scores.append(score) #add to list\n",
        "\n",
        "    return np.mean(roc_scores)\n",
        "\n",
        "# Test it now\n",
        "final_score = evaluate()\n",
        "print(f\"ðŸŽ¯ Final Test ROC-AUC: {final_score:.4f}\")"
      ],
      "metadata": {
        "id": "4XuJ837jDD_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_toxicity(smiles_string):\n",
        "    # Switch model to \"Eval\" mode (turns off Dropout)\n",
        "    model.eval()\n",
        "\n",
        "    # Convert string to Graph\n",
        "    # We pass label=None because we don't know the answer yet\n",
        "    data = smiles_to_pyg(smiles_string, label=None)\n",
        "\n",
        "    if data is None:\n",
        "        return \"âŒ Error: Could not parse molecule.\"\n",
        "\n",
        "    # Move data to the same device as the model (GPU or CPU)\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Create a \"Batch\" of size 1\n",
        "    # The model expects a batch, even if it's just one item\n",
        "    batch_idx = torch.zeros(data.num_nodes, dtype=torch.long).to(device)\n",
        "\n",
        "    # Run the Model\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index, batch_idx)\n",
        "        probs = torch.sigmoid(logits) # Convert logits to 0-1 probabilities\n",
        "\n",
        "    return probs.cpu().numpy().flatten()"
      ],
      "metadata": {
        "id": "9WjBk6HH8e2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Figuring out what the 12 task names are\n",
        "task_names = [c for c in df.columns if c not in ['smiles', 'mol_id']]\n",
        "print(task_names)"
      ],
      "metadata": {
        "id": "roJlha6c8gbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a way to access smiles based on simply using pubchem's API\n",
        "\n",
        "def get_smiles_from_name(compound_name):\n",
        "  try:\n",
        "    compounds = pcp.get_compounds(compound_name, 'name')\n",
        "\n",
        "    if compounds:\n",
        "      smiles = compounds[0].canonical_smiles\n",
        "      return smiles\n",
        "    else:\n",
        "      print(f\"Compound '{compound_name}' could not be found\")\n",
        "      return None\n",
        "\n",
        "  except Exception as e:\n",
        "        print(f\"Error connecting to PubChem: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def tester(compound_name):\n",
        "  smiles_str = get_smiles_from_name(compound_name)\n",
        "\n",
        "  if smiles_str:\n",
        "    probs = predict_toxicity(smiles_str)\n",
        "\n",
        "    print(f\"\\nTesting ðŸ§ª Toxicity Report for {compound_name}...\")\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    for i, task in enumerate(task_names):\n",
        "        risk = probs[i]\n",
        "        # Highlight high risks in RED\n",
        "        flag = \"ðŸ”´ HIGH RISK\" if risk > 0.5 else \"ðŸŸ¢ Safe\"\n",
        "        print(f\"{task:<15} | {risk:.4f} | {flag}\") # Need to adjust this so it's readable\n",
        "  else:\n",
        "    print(\"Error with testing toxicity of compound\")\n",
        "\n",
        "tester(\"tylenol\")"
      ],
      "metadata": {
        "id": "J-9ZxKx98hh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing GNN explainer portion\n",
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "\n"
      ],
      "metadata": {
        "id": "PVDcuqvCT0UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pubchempy as pcp\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "def visualize_custom(data, explanation, title):\n",
        "    # Extract edge importance\n",
        "    edge_mask = explanation.edge_mask.cpu().detach().numpy()\n",
        "\n",
        "    # Create NetworkX graph\n",
        "    G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    pos = nx.spring_layout(G, seed=42) # Consistent layout\n",
        "\n",
        "    # Draw non-important edges (faint)\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.2, width=1)\n",
        "\n",
        "    # Draw nodes\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=300, node_color='#add8e6')\n",
        "\n",
        "    # Draw IMPORTANT edges (The \"Toxic\" Pharmacophore)\n",
        "    # Threshold: We only show edges that contributed > 60% to the decision\n",
        "    threshold = 0.6\n",
        "    high_importance_edges = []\n",
        "\n",
        "    # Map edge_mask back to NetworkX edges\n",
        "    # (PyG edge_index and NetworkX edges might differ in order, so we iterate carefully)\n",
        "    for i, (u, v) in enumerate(data.edge_index.t().cpu().numpy()):\n",
        "        if edge_mask[i] > threshold:\n",
        "            # Add edge to list (NetworkX handles undirected duplicates visually)\n",
        "            high_importance_edges.append((u, v))\n",
        "\n",
        "    if high_importance_edges:\n",
        "        nx.draw_networkx_edges(G, pos, edgelist=high_importance_edges,\n",
        "                               width=4, edge_color='red')\n",
        "\n",
        "    plt.title(f\"Why is {title} Toxic?\\n(Red Bonds = High Attention)\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def explain_new_molecule(compound_name):\n",
        "    print(f\"Fetching {compound_name} from PubChem...\")\n",
        "\n",
        "    # Get SMILES\n",
        "    try:\n",
        "        compounds = pcp.get_compounds(compound_name, 'name')\n",
        "        if not compounds:\n",
        "            print(\"Compound not found.\")\n",
        "            return\n",
        "        # Use connectivity_smiles to avoid the DeprecationWarning\n",
        "        smiles = compounds[0].canonical_smiles\n",
        "    except Exception as e:\n",
        "        print(f\"Connection Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # Graph Conversion\n",
        "    data = smiles_to_pyg(smiles)\n",
        "    if data is None:\n",
        "        print(\"Could not featurize molecule.\")\n",
        "        return\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    batch_idx = torch.zeros(data.num_nodes, dtype=torch.long).to(device)\n",
        "\n",
        "    logits = model(data.x, data.edge_index, batch_idx)\n",
        "    probs = torch.sigmoid(logits).detach().cpu().numpy().flatten()\n",
        "\n",
        "    target_task_idx = probs.argmax()\n",
        "    highest_risk = probs[target_task_idx]\n",
        "\n",
        "    print(f\"Analysis: {compound_name}\")\n",
        "    print(f\"Top Risk: {task_names[target_task_idx]} ({highest_risk:.4f})\")\n",
        "\n",
        "    if highest_risk < 0.5:\n",
        "        print(\"âœ… Model thinks this is SAFE. Explainer might be noisy.\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Model thinks this is TOXIC. Generating explanation...\")\n",
        "\n",
        "    # 4. Run Explainer\n",
        "    explanation = explainer(\n",
        "        x=data.x,\n",
        "        edge_index=data.edge_index,\n",
        "        batch=batch_idx,\n",
        "        index=0,  # <--- fixed: Always 0 because we have 1 graph\n",
        "        target=torch.tensor([target_task_idx]).to(device) # Focus on the specific toxic task\n",
        "    )\n",
        "\n",
        "    # 5. Visualize\n",
        "    visualize_custom(data, explanation, compound_name)"
      ],
      "metadata": {
        "id": "eclGelugUsuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a known toxic compound\n",
        "explain_new_molecule(\"Chlorpyrifos\")"
      ],
      "metadata": {
        "id": "rNU6nkHUUuYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}